g <- ggplotGrob(plots[[1]] + theme(legend.position = position))$grobs
legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
lheight <- sum(legend$height)
lwidth <- sum(legend$width)
gl <- lapply(plots, function(x) x + theme(legend.position="none"))
gl <- c(gl, ncol = ncol, nrow = nrow)
combined <- switch(position,
"bottom" = arrangeGrob(do.call(arrangeGrob, gl),
legend,
ncol = 1,
heights = unit.c(unit(1, "npc") - lheight, lheight)),
"right" = arrangeGrob(do.call(arrangeGrob, gl),
legend,
ncol = 2,
labels = c("A", "B"),
widths = unit.c(unit(1, "npc") - lwidth, lwidth)))
grid.newpage()
grid.draw(combined)
}
plot1 <- am.map
plot2 <- eur.map
grid_arrange_shared_legend(plot1, plot2, ncol = 2,
widths = c(2.8, 2.8), heights = 2.2)
grid_arrange_shared_legend <- function(..., ncol = length(list(...)), nrow = 1, position = c("bottom", "right")) {
plots <- list(...)
position <- match.arg(position)
g <- ggplotGrob(plots[[1]] + theme(legend.position = position))$grobs
legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
lheight <- sum(legend$height)
lwidth <- sum(legend$width)
gl <- lapply(plots, function(x) x + theme(legend.position="none"))
gl <- c(gl, ncol = ncol, nrow = nrow)
combined <- switch(position,
"bottom" = arrangeGrob(do.call(arrangeGrob, gl),
legend,
ncol = 1,
heights = unit.c(unit(1, "npc") - lheight, lheight)),
"right" = arrangeGrob(do.call(arrangeGrob, gl),
legend,
ncol = 2,
widths = unit.c(unit(1, "npc") - lwidth, lwidth)))
grid.newpage()
grid.draw(combined)
}
plot1 <- am.map
plot2 <- eur.map
grid_arrange_shared_legend(plot1, plot2, ncol = 2, labels = c("A", "B"),
widths = c(2.8, 2.8), heights = 2.2)
plot_grid(plot1, plot2, labels=c("A", "B"), ncol = 2, nrow = 1)
install.packages("cowplot")
library(cowplot)
plot_grid(plot1, plot2, labels=c("A", "B"), ncol = 2, nrow = 1)
eur.map <- eur + geom_point(data = europe, aes(Longitude, Latitude, size=False.Springs, color=False.Springs)) +
scale_color_gradient(low="red", high="blue", name="Number of False Springs")  +
guides(size=FALSE)
plot2 <- eur.map
plot_grid(plot1, plot2, labels=c("A", "B"), ncol = 2, nrow = 1)
legend <- get_legend(eur.map)
eur.map <- eur.map + theme(legend.position="none")
grid.arrange(am.map, eur.map, legend, ncol=3, widths=c(2.3, 2.3, 0.8), labels = c("A", "B"))
grid.arrange(am.map, eur.map, legend, ncol=3, widths=c(2.8, 2.8, 0.8), labels = c("A", "B"))
grid.arrange(am.map, eur.map, legend, ncol=3, widths=c(2.8, 2.8, 0.8), labels = c("A", "B", ""))
grid.arrange(am.map, eur.map, legend, ncol=2, nrow = 2,
layout_matrix = rbind(c(1,2), c(3,3)),
widths = c(2.7, 2.7), heights = c(2.5, 0.2))
grid.arrange(am.map, eur.map, legend, ncol=3, widths=c(2.8, 2.8, 0.8))
plot_grid(plot1, plot2, labels=c("A", "B"), ncol = 2, nrow = 1)
plot_grid(plot1, eur.map, labels=c("A", "B"), ncol = 2, nrow = 1)
grid_arrange_shared_legend(plot1, plot2, ncol = 2, labels = c("A", "B"),
widths = c(2.8, 2.8), heights = 2.2)
grid_arrange_shared_legend(plot1, plot2, ncol = 2,
widths = c(2.8, 2.8), heights = 2.2)
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
### The power of Sunny Delight
## Kids who drink sunny d at a young age are more likely to be happier adults
## In our example, if a child drinks 1 bottle of sunny d a week at the age of 5,
# then the amount of dopamine in the brain increases in adulthood.
## The average adult has 45+/-5 ng/ml of dopamine, but kids who drink sunny d
# increase that level to 55 ng/ml
## The first study tests 1000 kids
library(arm)
library(ggplot2)
library(gridExtra)
## What is the effect size in this example?
ES = (55-45)/5 ## ES = 2
SE = 5/(sqrt(10)) ## SE = 0.16
## What about when we triple the effect size?
ES = (75-45)/5 ## ES = 6
SE = 5/(sqrt(10)) ## SE stays the same
## How about when we triple the sample size?
ES = (55-45)/5 ## ES is 2 like before but...
SE = 5/(sqrt(30)) ## SE decreases slightly - SE = 0.09
### Andrew states that " it is generally better to double the effect size [theta] than to double the sample size [n]"
## here we can see that doubling the sample size decreases the standard error at a slower rate than doubling the effect size
# The SE: effect size influences the numerator, sample size influences the denominator
nsunny = 2
rep = 5
ntot = nsunny*rep
sunny = gl(nsunny, rep, length=ntot)
sunnydiff = 10
sunnydiff.sd = 0
suns<-rnorm(ntot, 55, 5)
base <- 45
child <- base + suns-mean(suns)
mm <- model.matrix(~(sunny)^2, data.frame=(sunny))
fake <- vector()
for (i in 1:length(ntot)){
coeff <- c(child[i],
rnorm(1, sunnydiff, sunnydiff.sd)
)
dp <- rnorm(n = length(sunny), mean = mm %*% coeff, sd = 5)
fake <- data.frame(dp=dp, sunny=sunny)
}
hist(fake$dp[sunny==1])
hist(fake$dp[sunny==2])
mean(fake$dp) # 50.5
sd(fake$dp) # 7.24
display(lm(dp~sunny, data=fake))
#lm(formula = dp ~ sunny, data = fake)
#coef.est coef.se
#(Intercept) 45.33     0.23
#sunny2      10.25     0.32
#---
#  n = 1000, k = 2
#residual sd = 5.11, R-Squared = 0.50
### Alright, now let's triple the effect size...
### Sunny D increases the level of dopamine to 75 ng/ml - we'll keep the sample size the same
nsunny.e = 2
rep.e = 5
ntot.e = nsunny.e*rep.e
sunny.e = gl(nsunny.e, rep.e, length=ntot.e)
sunnydiff.e = 30
sunnydiff.sd.e = 0
suns.e<-rnorm(ntot.e, 75, 5)
base.e <- 45
child.e <- base.e + suns.e-mean(suns.e)
mm.e <- model.matrix(~(sunny.e)^2, data.frame=(sunny.e))
fake.e <- vector()
for (i in 1:length(ntot.e)){
coeff.e <- c(child.e[i],
rnorm(1, sunnydiff.e, sunnydiff.sd.e)
)
dp.e <- rnorm(n = length(sunny.e), mean = mm.e %*% coeff.e, sd = 5)
fake.e <- data.frame(dp.e=dp.e, sunny.e=sunny.e)
}
hist(fake.e$dp.e[sunny.e==1])
hist(fake.e$dp.e[sunny.e==2])
mean(fake.e$dp.e) # 61.2
sd(fake.e$dp.e) # 15.9
display(lm(dp.e~sunny.e, data=fake.e))
#lm(formula = dp.e ~ sunny.e, data = fake.e)
#coef.est coef.se
#(Intercept) 46.04     0.22
#sunny.e2    30.24     0.31
#---
#  n = 1000, k = 2
#residual sd = 4.94, R-Squared = 0.90
## And now, we triple the sample size...
nsunny.s = 2
rep.s = 15
ntot.s = nsunny.s*rep.s
sunny.s = gl(nsunny.s, rep.s, length=ntot.s)
sunnydiff.s = 10
sunnydiff.sd.s = 0
suns.s<-rnorm(ntot.s, 55, 5)
base.s <- 45
child.s <- base.s + suns.s-mean(suns.s)
mm.s <- model.matrix(~(sunny.s)^2, data.frame=(sunny.s))
fake.s <- vector()
for (i in 1:length(ntot.s)){
coeff.s <- c(child.s[i],
rnorm(1, sunnydiff.s, sunnydiff.sd.s)
)
dp.s <- rnorm(n = length(sunny.s), mean = mm.s %*% coeff.s, sd = 5)
fake.s <- data.frame(dp.s=dp.s, sunny.s=sunny.s)
}
hist(fake.s$dp.s)
mean(fake.s$dp.s) # 52.8
sd(fake.s$dp.s) # 6.93
display(lm(dp.s~sunny.s, data=fake.s))
#lm(formula = dp.s ~ sunny.s, data = fake.s)
#coef.est coef.se
#(Intercept) 48.01     0.13
#sunny.s2     9.66     0.18
#---
#  n = 3000, k = 2
#residual sd = 4.97, R-Squared = 0.49
#### Let's plot the effects!
fake$sunny<-ifelse(fake$sunny==1, "control", "sunnyD")
base<- qplot(sunny, dp, data = fake, geom="boxplot", color=sunny) +
xlab("Sunny D consumption") + ylab("Dopamine levels (ng/ml)") + ylim(30,85)
fake.e$sunny.e<-ifelse(fake.e$sunny.e==1, "control", "sunnyD")
effect<- qplot(sunny.e, dp.e, data = fake.e, geom="boxplot", color=sunny.e) +
xlab("Sunny D consumption") + ylab("Dopamine levels (ng/ml)") + ylim(30,85)
fake.s$sunny.s<-ifelse(fake.s$sunny.s==1, "control", "sunnyD")
sample<- qplot(sunny.s, dp.s, data = fake.s, geom="boxplot", color=sunny.s) +
xlab("Sunny D consumption") + ylab("Dopamine levels (ng/ml)") + ylim(30,85)
grid.arrange(base, effect, sample, ncol=3, nrow=1)
fake$child<- as.numeric(sample(1000))
fake.e$child.e<-as.numeric(sample(1000))
fake.s$child.s<-as.numeric(sample(3000))
bg<-ggplot(fake, aes(x=child, y=dp)) + geom_point(aes(color=sunny)) + geom_smooth(method="lm")
#bh<-hist(fake$dp)
#grid.arrange(bg,bh, ncol=1, nrow=2)
eg<-ggplot(fake.e, aes(x=child.e, y=dp.e)) + geom_point(aes(color=sunny.e)) + geom_smooth(method="lm")
#eh<-hist(fake.e$dp.e)
#grid.arrange(eg,eh, ncol=1, nrow=2)
sg<-ggplot(fake.s, aes(x=child.s, y=dp.s)) + geom_point(aes(color=sunny.s)) + geom_smooth(method="lm")
#sh<-hist(fake.s$dp.s)
#grid.arrange(sg,sh, ncol=1, nrow=2)
grid.arrange(bg,eg,sg, ncol=3, nrow=1)
fake$child<- as.numeric(sample(10))
fake.e$child.e<-as.numeric(sample(10))
fake.s$child.s<-as.numeric(sample(30))
bg<-ggplot(fake, aes(x=child, y=dp)) + geom_point(aes(color=sunny)) + geom_smooth(method="lm")
eg<-ggplot(fake.e, aes(x=child.e, y=dp.e)) + geom_point(aes(color=sunny.e)) + geom_smooth(method="lm")
sg<-ggplot(fake.s, aes(x=child.s, y=dp.s)) + geom_point(aes(color=sunny.s)) + geom_smooth(method="lm")
grid.arrange(bg,eg,sg, ncol=3, nrow=1)
library(arm)
library(ggplot2)
library(gridExtra)
## What is the effect size in this example?
ES = (55-45)/5 ## ES = 2
SE = 5/(sqrt(100)) ## SE = 0.16
## What about when we triple the effect size?
ES = (75-45)/5 ## ES = 6
SE = 5/(sqrt(100)) ## SE stays the same
## How about when we triple the sample size?
ES = (55-45)/5 ## ES is 2 like before but...
SE = 5/(sqrt(300)) ## SE decreases slightly - SE = 0.09
### Andrew states that " it is generally better to double the effect size [theta] than to double the sample size [n]"
## here we can see that doubling the sample size decreases the standard error at a slower rate than doubling the effect size
# The SE: effect size influences the numerator, sample size influences the denominator
nsunny = 2
rep = 50
ntot = nsunny*rep
sunny = gl(nsunny, rep, length=ntot)
sunnydiff = 10
sunnydiff.sd = 0
suns<-rnorm(ntot, 55, 5)
base <- 45
child <- base + suns-mean(suns)
mm <- model.matrix(~(sunny)^2, data.frame=(sunny))
fake <- vector()
for (i in 1:length(ntot)){
coeff <- c(child[i],
rnorm(1, sunnydiff, sunnydiff.sd)
)
dp <- rnorm(n = length(sunny), mean = mm %*% coeff, sd = 5)
fake <- data.frame(dp=dp, sunny=sunny)
}
hist(fake$dp[sunny==1])
hist(fake$dp[sunny==2])
mean(fake$dp) # 50.5
sd(fake$dp) # 7.24
display(lm(dp~sunny, data=fake))
#lm(formula = dp ~ sunny, data = fake)
#coef.est coef.se
#(Intercept) 45.33     0.23
#sunny2      10.25     0.32
#---
#  n = 1000, k = 2
#residual sd = 5.11, R-Squared = 0.50
### Alright, now let's triple the effect size...
### Sunny D increases the level of dopamine to 75 ng/ml - we'll keep the sample size the same
nsunny.e = 2
rep.e = 50
ntot.e = nsunny.e*rep.e
sunny.e = gl(nsunny.e, rep.e, length=ntot.e)
sunnydiff.e = 30
sunnydiff.sd.e = 0
suns.e<-rnorm(ntot.e, 75, 5)
base.e <- 45
child.e <- base.e + suns.e-mean(suns.e)
mm.e <- model.matrix(~(sunny.e)^2, data.frame=(sunny.e))
fake.e <- vector()
for (i in 1:length(ntot.e)){
coeff.e <- c(child.e[i],
rnorm(1, sunnydiff.e, sunnydiff.sd.e)
)
dp.e <- rnorm(n = length(sunny.e), mean = mm.e %*% coeff.e, sd = 5)
fake.e <- data.frame(dp.e=dp.e, sunny.e=sunny.e)
}
hist(fake.e$dp.e[sunny.e==1])
hist(fake.e$dp.e[sunny.e==2])
mean(fake.e$dp.e) # 61.2
sd(fake.e$dp.e) # 15.9
display(lm(dp.e~sunny.e, data=fake.e))
#lm(formula = dp.e ~ sunny.e, data = fake.e)
#coef.est coef.se
#(Intercept) 46.04     0.22
#sunny.e2    30.24     0.31
#---
#  n = 1000, k = 2
#residual sd = 4.94, R-Squared = 0.90
## And now, we triple the sample size...
nsunny.s = 2
rep.s = 150
ntot.s = nsunny.s*rep.s
sunny.s = gl(nsunny.s, rep.s, length=ntot.s)
sunnydiff.s = 10
sunnydiff.sd.s = 0
suns.s<-rnorm(ntot.s, 55, 5)
base.s <- 45
child.s <- base.s + suns.s-mean(suns.s)
mm.s <- model.matrix(~(sunny.s)^2, data.frame=(sunny.s))
fake.s <- vector()
for (i in 1:length(ntot.s)){
coeff.s <- c(child.s[i],
rnorm(1, sunnydiff.s, sunnydiff.sd.s)
)
dp.s <- rnorm(n = length(sunny.s), mean = mm.s %*% coeff.s, sd = 5)
fake.s <- data.frame(dp.s=dp.s, sunny.s=sunny.s)
}
hist(fake.s$dp.s)
mean(fake.s$dp.s) # 52.8
sd(fake.s$dp.s) # 6.93
display(lm(dp.s~sunny.s, data=fake.s))
#lm(formula = dp.s ~ sunny.s, data = fake.s)
#coef.est coef.se
#(Intercept) 48.01     0.13
#sunny.s2     9.66     0.18
#---
#  n = 3000, k = 2
#residual sd = 4.97, R-Squared = 0.49
#### Let's plot the effects!
fake$sunny<-ifelse(fake$sunny==1, "control", "sunnyD")
base<- qplot(sunny, dp, data = fake, geom="boxplot", color=sunny) +
xlab("Sunny D consumption") + ylab("Dopamine levels (ng/ml)") + ylim(30,85)
fake.e$sunny.e<-ifelse(fake.e$sunny.e==1, "control", "sunnyD")
effect<- qplot(sunny.e, dp.e, data = fake.e, geom="boxplot", color=sunny.e) +
xlab("Sunny D consumption") + ylab("Dopamine levels (ng/ml)") + ylim(30,85)
fake.s$sunny.s<-ifelse(fake.s$sunny.s==1, "control", "sunnyD")
sample<- qplot(sunny.s, dp.s, data = fake.s, geom="boxplot", color=sunny.s) +
xlab("Sunny D consumption") + ylab("Dopamine levels (ng/ml)") + ylim(30,85)
grid.arrange(base, effect, sample, ncol=3, nrow=1)
fake$child<- as.numeric(sample(100))
fake.e$child.e<-as.numeric(sample(100))
fake.s$child.s<-as.numeric(sample(300))
bg<-ggplot(fake, aes(x=child, y=dp)) + geom_point(aes(color=sunny)) + geom_smooth(method="lm")
eg<-ggplot(fake.e, aes(x=child.e, y=dp.e)) + geom_point(aes(color=sunny.e)) + geom_smooth(method="lm")
sg<-ggplot(fake.s, aes(x=child.s, y=dp.s)) + geom_point(aes(color=sunny.s)) + geom_smooth(method="lm")
grid.arrange(bg,eg,sg, ncol=3, nrow=1)
display(mod.base);display(mod.e);display(mod.s)
mod.base<-lm(dp~sunny, data=fake)
mod.e<-lm(dp.e~sunny.e, data=fake.e)
mod.s<-lm(dp.s~sunny.s, data=fake.s)
display(mod.base);display(mod.e);display(mod.s)
rm(list=ls())
options(stringsAsFactors = FALSE)
# dostan = TRUE
library(rstan)
#install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
library(ggplot2)
library(shinystan)
library(bayesplot)
library(rstanarm)
# Setting working directory. Add in your own path in an if statement for your file structure
setwd("~/Documents/git/freezingexperiment/analyses/")
source('scripts/savestan.R')
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
########################
#### get the data
bb<-read.csv("output/percentBB_betula.csv", header=TRUE)
bb<-read.csv("output/fakebeta.csv", header=TRUE)
## make a bunch of things numeric
bb$tx<-ifelse(bb$tx=="A", 0, 1)
bb$sp <- as.numeric(as.factor(bb$sp))
bb$perc <- as.numeric(bb$perc)
bb$perc <- bb$perc/100
## subsetting data, preparing genus variable, removing NAs
pp.prepdata <- subset(bb, select=c("perc", "tx", "sp")) # removed "sp" when doing just one species
pp.stan <- pp.prepdata[complete.cases(pp.prepdata),]
perc = pp.stan$perc
tx = pp.stan$tx
sp = pp.stan$sp
N = length(perc)
# making a list out of the processed data. It will be input for the model
datalist.td <- list(perc=perc,tx=tx,sp=sp,N=N)
View(bb)
bb<-read.csv("output/birches_clean.csv", header=TRUE)
View(bb)
bb$tx<-ifelse(bb$tx=="A", 0, 1)
bb$sp <- as.numeric(as.factor(bb$sp))
View(bb)
bb$dvr <- as.numeric(bb$dvr)
bb$ind<-substr(bb$individ, 9,10)
dvr.prepdata <- subset(bb, select=c("dvr", "tx", "ind", "sp")) # removed "sp" when doing just one species
dvr.stan <- dvr.prepdata[complete.cases(dvr.prepdata),]
View(dvr.stan)
bb<-read.csv("output/percentBB_betula.csv", header=TRUE)
bb$tx<-ifelse(bb$tx=="A", 0, 1)
bb$sp <- as.numeric(as.factor(bb$sp))
View(bb)
bb$perc <- as.numeric(bb$perc)
bb$perc <- bb$perc/100
pp.prepdata <- subset(bb, select=c("perc", "tx", "sp")) # removed "sp" when doing just one species
pp.stan <- pp.prepdata[complete.cases(pp.prepdata),]
perc = pp.stan$perc
tx = pp.stan$tx
sp = pp.stan$sp
N = length(perc)
datalist.td <- list(perc=perc,tx=tx,sp=sp,N=N) # removed sp=sp and n_sp=s_sp for one species
fit1<-stan_betareg(perc~tx+sp, data=pp.stan)
fit1
plot(fit1, pars="beta")
prior_summary(fit1)
plot(fit1, pars=c("tx","sp"))
rm(list=ls())
options(stringsAsFactors = FALSE)
# dostan = TRUE
library(rstan)
#install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
library(ggplot2)
library(shinystan)
library(bayesplot)
library(rstanarm)
# Setting working directory. Add in your own path in an if statement for your file structure
setwd("~/Documents/git/freezingexperiment/analyses/")
source('scripts/savestan.R')
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
########################
#### get the data
bb<-read.csv("output/birches_clean.csv", header=TRUE)
bb<-read.csv("output/fakedata_exp.csv", header=TRUE)
dvr.prepdata <- subset(bb, select=c("dvr", "tx", "ind", "sp")) # removed "sp" when doing just one species
dvr.stan <- dvr.prepdata[complete.cases(dvr.prepdata),]
dvr.stan$ind <- as.numeric(as.factor(dvr.stan$ind))
dvr = dvr.stan$dvr
tx = dvr.stan$tx
ind = dvr.stan$ind
sp = dvr.stan$sp
N = length(dvr)
n_ind = length(unique(dvr.stan$ind))
n_sp = length(unique(dvr.stan$sp))
# making a list out of the processed data. It will be input for the model
datalist.td <- list(dvr=dvr,tx=tx,sp=sp, ind=ind,N=N,n_ind=n_ind, n_sp=n_sp) # removed sp=sp and n_sp=s_sp for one species
fit1<-stan_glmer(dvr~tx+sp+(1|ind), data=dvr.stan)
fit1
rm(list=ls())
options(stringsAsFactors = FALSE)
# dostan = TRUE
library(rstan)
#install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
library(ggplot2)
library(shinystan)
library(bayesplot)
library(rstanarm)
# Setting working directory. Add in your own path in an if statement for your file structure
setwd("~/Documents/git/freezingexperiment/analyses/")
source('scripts/savestan.R')
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
########################
#### get the data
bb<-read.csv("output/birches_clean.csv", header=TRUE)
bb$tx<-ifelse(bb$tx=="A", 0, 1)
bb$sp <- as.numeric(as.factor(bb$sp))
bb$dvr <- as.numeric(bb$dvr)
bb$ind<-substr(bb$individ, 9,10)
## subsetting data, preparing genus variable, removing NAs
dvr.prepdata <- subset(bb, select=c("dvr", "tx", "ind", "sp")) # removed "sp" when doing just one species
dvr.stan <- dvr.prepdata[complete.cases(dvr.prepdata),]
dvr.stan$ind <- as.numeric(as.factor(dvr.stan$ind))
dvr = dvr.stan$dvr
tx = dvr.stan$tx
ind = dvr.stan$ind
sp = dvr.stan$sp
N = length(dvr)
n_ind = length(unique(dvr.stan$ind))
n_sp = length(unique(dvr.stan$sp))
# making a list out of the processed data. It will be input for the model
datalist.td <- list(dvr=dvr,tx=tx,sp=sp, ind=ind,N=N,n_ind=n_ind, n_sp=n_sp) # removed sp=sp and n_sp=s_sp for one species
##############################
###### real data rstanarm first
fit1<-stan_glmer(dvr~tx+sp+(1|ind), data=dvr.stan)
fit1
bb<-read.csv("output/fakebeta.csv", header=TRUE)
pp.prepdata <- subset(bb, select=c("perc", "tx", "sp")) # removed "sp" when doing just one species
pp.stan <- pp.prepdata[complete.cases(pp.prepdata),]
perc = pp.stan$perc
tx = pp.stan$tx
sp = pp.stan$sp
N = length(perc)
# making a list out of the processed data. It will be input for the model
datalist.td <- list(perc=perc,tx=tx,sp=sp,N=N) # removed sp=sp and n_sp=s_sp for one species
##############################
###### real data rstanarm first
fit1<-stan_betareg(perc~tx+sp, data=pp.stan)
fit1
bb<-read.csv("output/percentBB_betula.csv", header=TRUE)
bb$tx<-ifelse(bb$tx=="A", 0, 1)
bb$sp <- as.numeric(as.factor(bb$sp))
bb$perc <- as.numeric(bb$perc)
bb$perc <- bb$perc/100
## subsetting data, preparing genus variable, removing NAs
pp.prepdata <- subset(bb, select=c("perc", "tx", "sp")) # removed "sp" when doing just one species
pp.stan <- pp.prepdata[complete.cases(pp.prepdata),]
perc = pp.stan$perc
tx = pp.stan$tx
sp = pp.stan$sp
N = length(perc)
# making a list out of the processed data. It will be input for the model
datalist.td <- list(perc=perc,tx=tx,sp=sp,N=N) # removed sp=sp and n_sp=s_sp for one species
##############################
###### real data rstanarm first
fit1<-stan_betareg(perc~tx+sp, data=pp.stan)
fit1
